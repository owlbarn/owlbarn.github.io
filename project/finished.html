
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Finished Sub-Projects &#8212; Owl Numerical Library 0.3 documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="How-To?" href="../chapter/howto.html" />
    <link rel="prev" title="Proposed Sub-Projects" href="proposal.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/owl_logo_4.png" alt="Logo"/>
    
  </a>
</p>











  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Finished Sub-Projects</a><ul>
<li><a class="reference internal" href="#probabilistic-synchronous-parallel">Probabilistic Synchronous Parallel</a></li>
<li><a class="reference internal" href="#supporting-browser-based-machine-learning">Supporting Browser-based Machine Learning</a></li>
<li><a class="reference internal" href="#adaptable-asynchrony-in-distributed-learning">Adaptable Asynchrony in Distributed Learning</a></li>
<li><a class="reference internal" href="#applications-of-linear-types">Applications of Linear Types</a></li>
<li><a class="reference internal" href="#composing-data-analytical-services">Composing Data Analytical Services</a></li>
<li><a class="reference internal" href="#computer-vision-performance-optimisation-of-computation-graph">Computer Vision &amp; Performance Optimisation of Computation Graph</a></li>
<li><a class="reference internal" href="#automatic-parameter-tuning-for-openmp">Automatic Parameter Tuning for OpenMP</a></li>
<li><a class="reference internal" href="#run-your-owl-computation-on-tensorflow">Run Your Owl Computation on TensorFlow</a></li>
<li><a class="reference internal" href="#ordinary-differential-equation-solver">Ordinary Differential Equation Solver</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="../chapter/index.html">Owl Numerical System</a><ul>
      <li>Previous: <a href="proposal.html" title="previous chapter">Proposed Sub-Projects</a></li>
      <li>Next: <a href="../chapter/howto.html" title="next chapter">How-To?</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="finished-sub-projects">
<h1>Finished Sub-Projects<a class="headerlink" href="#finished-sub-projects" title="Permalink to this headline">¶</a></h1>
<p>This page maintains a list of finished projects including a brief description and its outcome. If you think your project is relevant to Owl and want to be included in the list on this page, please contact me directly.</p>
<div class="section" id="probabilistic-synchronous-parallel">
<h2>Probabilistic Synchronous Parallel<a class="headerlink" href="#probabilistic-synchronous-parallel" title="Permalink to this headline">¶</a></h2>
<p>By <strong>Benjamin P. W. Catterall</strong> | Part III | June 2017 | <a class="reference download internal" download="" href="../_downloads/07586e16e6d6a41e4a10755a92827b08/catterall.pdf"><code class="xref download docutils literal notranslate"><span class="pre">{Thesis}</span></code></a>  <a class="reference external" href="https://arxiv.org/abs/1709.07772">{ArXiv 1709}</a></p>
<p>The synchronisation scheme used to manage parallel updates of a distributed machine learning model can dramatically impact performance. System and algorithm designers need methods which allow them to make trade-offs between fully asynchronous and fully deterministic schemes. Barrier control methods represent one possible solution. In this report, I present Probabilistic Synchronous Parallel (PSP), a barrier control method for distributed machine learning. I provide analytical proofs of convergence and carry out an experimental verification of the method using a bespoke simulator. I find that PSP improves the convergence speed and iteration throughput of more traditional barrier control methods. Furthermore, I demonstrate that PSP provides stronger convergence guarantees than a fully asynchronous design whilst maintaining the general characteristics of stronger methods.</p>
</div>
<div class="section" id="supporting-browser-based-machine-learning">
<h2>Supporting Browser-based Machine Learning<a class="headerlink" href="#supporting-browser-based-machine-learning" title="Permalink to this headline">¶</a></h2>
<p>By <strong>Tudor Petru Tiplea</strong> | Part III | June 2018 | <a class="reference download internal" download="" href="../_downloads/d37d6422f7df09f8b3f0fcf454542b67/tiplea.pdf"><code class="xref download docutils literal notranslate"><span class="pre">{Thesis}</span></code></a></p>
<p>Because it can tell so much about nature and people, digital data is collected and analysed in immeasurable quantities. Processing this data often requires collections of resources typically organised in massive data centres, a paradigm known as cloud computing. However, this paradigm has certain limitations. Apart from the often prohibitive costs, cloud computing requires data centralisation, which could slow down real-time applications, or require exorbitant storage. Edge computing—a solution aiming to move computation to the network’s edge — is regarded as a promising alternative, especially when tailored for Internet-of-Things deployment.</p>
<p>Aiming for more large-scale adoption, this project provides a proof of concept for edge computing support on an ubiquitous platform—the web-browser. This work is framed within an emerging OCaml ecosystem for data processing and machine learning applications. We explored options for OCaml-to-JavaScript compilation, and extended Owl, the main library in the ecosystem, guided by those findings. Next, we researched solutions for efficient data transmissions between browsers, then based on that, implemented a browser-compatible communication system analogous to TCP/IP network sockets. This system was later used to modify Actor, Owl’s distributed computing engine, making it deployable in the browser.</p>
<p>We demonstrated our work on Owl was successful, exemplifying the browser-deployed localised computing capabilities. The performance limitations of this part were analysed, and we suggest directions for optimisations based on empirical results. We also illustrated the accomplishment of browser-based distributed computing, again identifying limitations that must be overcome in the future for a complete solution.</p>
</div>
<div class="section" id="adaptable-asynchrony-in-distributed-learning">
<h2>Adaptable Asynchrony in Distributed Learning<a class="headerlink" href="#adaptable-asynchrony-in-distributed-learning" title="Permalink to this headline">¶</a></h2>
<p>By <strong>De Sheng Royson Lee</strong> | M.Phil | June 2018 | <a class="reference download internal" download="" href="../_downloads/717a3e7b659dc5d6045c7bdb8d1af831/royson.pdf"><code class="xref download docutils literal notranslate"><span class="pre">{Thesis}</span></code></a></p>
<p>Distributed training of deep learning models is typically trained using stochastic optimisation in an asynchronous or synchronous environment. Increasing asynchrony is known to add noise introduced from stale gradient updates, whereas relying on synchrony may be inefficient due to stragglers. Although there has been a wide range of approaches to mitigate or even negate these weaknesses, little has been done to improve asynchronous adaptive stochastic gradient descent (SGD) optimisation. In this report, I survey these approaches and propose a technique to better train these models. In addition, I empirically show that the technique works well with delay-tolerance adaptive SGD optimisation algorithms, improving the rate of convergence, stability, and test accuracy. I also demonstrate that my approach performs consistently well in a dynamic environment in which the number of workers changes uniformly at random.</p>
</div>
<div class="section" id="applications-of-linear-types">
<h2>Applications of Linear Types<a class="headerlink" href="#applications-of-linear-types" title="Permalink to this headline">¶</a></h2>
<p>By <strong>Dhruv C. Makwana</strong> | Part III | June 2018 | <a class="reference download internal" download="" href="../_downloads/739c2add6fdda5848baabcdb2af4797f/dhruv.pdf"><code class="xref download docutils literal notranslate"><span class="pre">{Thesis}</span></code></a>  <a class="reference external" href="https://github.com/dc-mak/lt4la/">{Github}</a></p>
<p>In this thesis, I argue that linear types are an appropriate, type-based formalism for expressing aliasing, read/write permissions, memory allocation, re-use and deallocation, first, in the context of the APIs of linear algebra libraries and then in the context of matrix expression compilation. I show that framing the problem using linear types can reduce bugs by making precise and explicit, the informal, ad-hoc practices typically employed by experts and matrix expression compilers and automate checking them.</p>
<p>As evidence for this argument, I show non-trivial, yet readable, linear algebra programs, that are safe and explicit (with respect to aliasing, read/write permissions, memory allocation, re-use and deallocation) which (1) are more memory-efficient than equivalent programs written using high- level linear algebra libraries and (2) perform just as predictably as equivalent programs written using low-level linear algebra libraries. I also argue the experience of writing such programs with linear types is qualitatively better in key respects. In addition to all of this, I show that it is possible to provide such features as a library on top of existing programming languages and linear algebra libraries.</p>
</div>
<div class="section" id="composing-data-analytical-services">
<h2>Composing Data Analytical Services<a class="headerlink" href="#composing-data-analytical-services" title="Permalink to this headline">¶</a></h2>
<p>By <strong>Jianxin Zhao</strong> | PhD | June 2018 | <a class="reference external" href="https://arxiv.org/abs/1805.05995">{ArXiv 1805}</a></p>
<p>Data analytics on the cloud is known to have issues such as increased response latency, communication cost, single point failure, and data privacy concerns. While moving analytics from cloud to edge devices has recently gained rapid growth in both academia and industry, this topic still faces many challenges such as limited computation resource on the edge. In this report, we further identify two main challenges: the composition and deployment of data analytics services on edge devices. Initially, the Zoo system is designed to make it convenient for developers to share and execute their OCaml code snippets, with fine-grained version control mechanism. We then extend it to address those two challenges. On one hand, Zoo provides simple domain-specific language and high-level types to enable easy and type-safe composition of different data analytics services. On the other hand, it utilises multiple deployment backends, including Docker container, JavaScript, and MirageOS, to accommodate the heterogeneous edge deployment environment. We demonstrate the expressiveness of Zoo with a use case, and thoroughly compare the performance of different deployment backends in evaluation.</p>
</div>
<div class="section" id="computer-vision-performance-optimisation-of-computation-graph">
<h2>Computer Vision &amp; Performance Optimisation of Computation Graph<a class="headerlink" href="#computer-vision-performance-optimisation-of-computation-graph" title="Permalink to this headline">¶</a></h2>
<p>By <strong>Pierre Vandenhove</strong> | MSc | October 2018 | <a class="reference external" href="https://github.com/owlbarn/owl-mask-rcnn">{MRCNN Github}</a> | <a class="reference external" href="https://arxiv.org/abs/1812.03770">{ArXiv 1812}</a> <a class="reference download internal" download="" href="../_downloads/f91fb73296d82ad0d56511efa898e33b/pierre.pdf"><code class="xref download docutils literal notranslate"><span class="pre">{Report}</span></code></a> | {<a class="reference internal" href="pierre_cgraph.html"><span class="doc">Computer Vision in OCaml</span></a>}</p>
<p>Computer vision tasks are known to be highly computationally-heavy, both performance-wise and memory-wise. They are thus especially relevant to put a numerical framework such as Owl to the test. The first part of this project focuses on the implementation of several computer vision applications using Owl’s neural network library. The first such application is Microsoft’s ‘ResNet’ network to perform simple image classification (<a class="reference external" href="https://arxiv.org/abs/1512.03385">paper 1512.03385</a>, <a class="reference external" href="https://github.com/pvdhove/owl-resnet">Resnet implementation in Owl</a>). The second, more extensive one, is ‘Mask R-CNN’, which is one of the leading networks to perform object detection, segmentation and classification (<a class="reference external" href="https://arxiv.org/abs/1703.06870">paper 1703.06870</a>, <a class="reference external" href="https://github.com/pvdhove/owl-mask-rcnn">MRCNN implementation</a>). This allowed exemplifying some use cases to improve Owl’s flexibility and ease of use, as well as add some necessary operations.</p>
<p>These applications are valuable benchmarking tools to identify bottlenecks and guide the optimisation of different subcomponents of Owl. A crucial step in this process is to apply Owl’s computation graph to them, which is the key to obtaining state-of-the-art performance and memory usage. With the new applications as examples, it was possible to make it more robust, efficient and user-friendly.</p>
</div>
<div class="section" id="automatic-parameter-tuning-for-openmp">
<h2>Automatic Parameter Tuning for OpenMP<a class="headerlink" href="#automatic-parameter-tuning-for-openmp" title="Permalink to this headline">¶</a></h2>
<p>By <strong>Jianxin Zhao</strong> | PhD | November 2018 | <a class="reference external" href="https://github.com/owlbarn/owl/tree/master/src/aeos">{AEOS Github}</a> | <a class="reference external" href="http://ocaml.xyz">{Thesis}</a> | {<a class="reference internal" href="jianxin_aeos.html"><span class="doc">Automated Empirical Optimisation of Parameters in Owl</span></a>}</p>
<p>Automatic Empirical Optimisation of Software (AEOS) is crucial for high performance computing software. It is a methodology to generate optimised software using empirically tuned parameters. As an initial attempt to improve the performance of Owl with it, we build the AEOS module to tune the OpenMP parameters in Owl. OpenMP is an application programming interface that supports multi-platform shared memory multiprocessing programming. It is used in Owl to boost performance of basic operations. However, using OpenMP brings certain overhead, so that when the size of input data is small, or the operation is simple, the non-OpenMP version operation might be faster. Thus an optimal threshold varies for different operations and machines. In the AEOS module, each operation is abstracted as a stand-alone module, and uses linear regression to find this optimal threshold. Compared with the previous practice of set a single threshold for all OpenMP operations, using AEOS module further improves their performance. The AEOS module is designed in such way that extending it to accommodate more parameters or operations should be easy.</p>
</div>
<div class="section" id="run-your-owl-computation-on-tensorflow">
<h2>Run Your Owl Computation on TensorFlow<a class="headerlink" href="#run-your-owl-computation-on-tensorflow" title="Permalink to this headline">¶</a></h2>
<p>By <strong>Jianxin Zhao</strong> | PhD | February 2019 | {<a class="reference internal" href="jianxin_cgraph.html"><span class="doc">Run Your Owl Computation on TensorFlow</span></a>}</p>
<p>In this project we are looking at computation interoperability of Owl with existing libraries such as TensorFlow.
Our target is to have the best of both worlds. On one hand, we can define “how to compute” on Owl with its elegant and powerful syntax; on the other hand, we can execute the computation efficiently across various hardware devices, such as GPU and TPU, that TensorFlow supports.
One crucial decision to make is to find the correct intermediate representation in exchanging computation between different platforms.
Unlike many existing systems and tools, we decide that computation graph, rather than neural network graph, should be the fundamental abstraction.
Based on this decision, we build an experimental converter system. It aims to export CGraph defined in Owl and execute it in TensorFlow.
This system centres around the abstraction of TensorFlow computation graph, and how to map Owl computation graph to it.
Our system utilises the Save and Restore mechanism in TensorFlow to provide a concise workflow.
Currently we are actively developing the system. Thought still quite limited at the initial phase, the system has shown its potential in real-world examples, including deep neural network inference and algorithmic differentiation.
In our next step, it would be interesting to see how our system can be extended and combined with related topics such as GPU and XLA.</p>
</div>
<div class="section" id="ordinary-differential-equation-solver">
<h2>Ordinary Differential Equation Solver<a class="headerlink" href="#ordinary-differential-equation-solver" title="Permalink to this headline">¶</a></h2>
<p>By <a class="reference external" href="https://github.com/tachukao">Ta-Chu Kao</a> and <a class="reference external" href="https://github.com/mseri">Marcello Seri</a> | July 2019 | <a class="reference external" href="https://github.com/owlbarn/owl_ode">{Owl-ODE Github}</a></p>
<p>Owl Ode is a lightweight package for solving ordinary differential equations. Built on top of Owl’s numerical library, Owl Ode was designed with extensibility and ease of use in mind and includes a number of classic ode solvers (e.g. Euler and Runge-Kutta, in both adaptive and fixed-step variants) and symplectic sovlers (e.g. Leapfrog), with more to come.</p>
<p>Taking full advantage of Owl’s automatic differentiation library, we plan on supporting a number of fully differentiable solvers, which can be used, for example, for <a class="reference external" href="https://github.com/tachukao/adjoint_ode/">training Neural ODEs</a>.</p>
<p>Currently, Owl Ode includes separately-released thin wrappers around Sundials Cvode (via sundialsml’s own wrapper) and ODEPACK, and native OCaml <a class="reference external" href="https://github.com/mseri/ocaml-cviode">contact variational integrators</a>. Going forward, we aim to expose more functions in Sundials and provide bindings for other battle-tested ODE solvers.</p>
</div>
</div>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>

    <div class="footer">
      &copy;2019, <a href="http://www.cl.cam.ac.uk/~lw525/">Liang Wang</a>   | <a href="http://www.cl.cam.ac.uk/">Computer Lab, University of Cambridge</a>.
      
      |
      <a href="../_sources/project/finished.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-123353217-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-123353217-1');
</script>

  </body>
</html>
